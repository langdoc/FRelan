---
title: "FRelan vignette"
author: "Niko Partanen"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{utf8}
---

FRelan package has been developed in Freiburg within the research project Izhva Komi Language Documentation, which has been funded by Kone Foundation in 2014-2016. The package can be used to parse ELAN files into a data frame, for which it is easy to perform different operations in R. Shiny corpus application FRorpus is integrated into FRelan, yet purposedly in rather limited form. This is done in order to maximize the compatibility with different data. FRelan is immediately compatible with the ELAN files we work with in Freiburg (IÅºva Komi, Kildin Saami, Skolt Saami, Pite Saami), but demands some modifications to the arguments when used with ELAN files that have different structure. Besides ELAN files, there is a simple function to read text files into similar dataframe as which would result from read_eaf() function. It seems to be the case that Python is currently more advanced with Natural Language Processing than R, but there are still many operations we may want to perform or test in R environment as well. There are projects such as rPython and rpy which allow moving functions and data between these languages. Thus the roles of R and Python in linguistic research should be seen primarily as complementary.

### What FRelan does?

As FRelan is in active development phase many functions are still somewhat limited. They focus currently to:

- Parsing whole ELAN corpus into one data frame
- Diagnosing malformed ELAN files

In addition to these tasks it does some rudimentary:

- Visualizing the content of ELAN files
- Allows some interaction with ELAN files from R

There are many functions that have been planned and which are maybe already rudimentarily tested, but which are not ready for more public distribution. Also some tools are so Komi dialectology specified that it is hard to see any more general use for them right now.

The main goal in developing the package has been to minimize exporting ELAN data to CSV in order to read them into R.

## Diagnosing malformed ELAN files

ELAN XML files are structurally valid XML files. However, if we want to use ELAN files as a corpus, we must assume that all data is structured in an uniform way. If there are structural differences, they must be explicitly stated and taken into account while making searches. I've encountered several reasons why some ELAN files end up being malformed, but the most commonly this is related to changes from one tier structure into another. These malformations may come in different forms:

- Wrongly named linguistic types
- Misspelled or empty PARTICIPANT tags
- Non-coherent hierarchy between tiers

These issues may not come up in normal ELAN searches, but when we parse ELAN XML into R or combine ELAN data with the metadata, it becomes very likely that these inconsistencies produce errors. In R environment they almost always come out as very visible errors, which, despite annoying, can also easily lead us to right tracks in eliminating the problems.

For now in this vignette I assume that all ELAN files are structurally coherent. I would advice a new user to take two "best" ELAN files and start with parsing them. It is very unlikely that parsing a very large amount of ELAN files at once would be immediately succesfull. However, it should be possible to modify the function `read_eaf()` so that it works with several well structured ELAN files.

